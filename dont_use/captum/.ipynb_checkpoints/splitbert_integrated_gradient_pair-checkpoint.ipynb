{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8991db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mykim/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-11-05 20:33:16.365508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.lang.en import English\n",
    "from splitbert.textsplit import text_segmentation\n",
    "from splitbert.splitbert import SplitBertConcatEncoderModel\n",
    "from splitbert.splitbert import conduct_input_ids_and_attention_masks\n",
    "from splitbert.splitbert import make_masks\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd1668f",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a53f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seg', 'seg', 'snt']\n",
      "10 4 10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "post_df = pd.read_csv('../predicting-satisfaction-using-graphs/csv/dataset/liwc_post.csv', encoding='UTF-8')\n",
    "comment_df = pd.read_csv('../predicting-satisfaction-using-graphs/csv/dataset/liwc_comment.csv', encoding='UTF-8')\n",
    "reply_df = pd.read_csv('../predicting-satisfaction-using-graphs/csv/dataset/avg_satisfaction_raw_0-999.csv', encoding='ISO-8859-1')\n",
    "\n",
    "modes = [['seg', 'seg', 'snt']]\n",
    "\n",
    "nlp = English()\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# satisfaction score (y)\n",
    "satisfactions_float = list(reply_df['satisfy_composite'])\n",
    "satisfactions = []\n",
    "\n",
    "for s in satisfactions_float:\n",
    "    if s < 3.5:\n",
    "        satisfactions.append(0)\n",
    "    elif s < 5:\n",
    "        satisfactions.append(1)\n",
    "    else:\n",
    "        satisfactions.append(2)\n",
    "\n",
    "reply_contents = list(reply_df['replyContent'])\n",
    "post_contents = list(post_df['content'])\n",
    "comment_bodies = list(comment_df['content'])\n",
    "\n",
    "\n",
    "def get_sequences(contents, mode):\n",
    "    sequences = []\n",
    "\n",
    "    if mode == 'all':\n",
    "        for content in contents:\n",
    "            sequences.append([content])\n",
    "    elif mode == 'seg':\n",
    "        for content in contents:\n",
    "            sentences = list(map(lambda x: str(x), list(nlp(content).sents)))\n",
    "            sequences.append(text_segmentation(sentences))\n",
    "    else:  # sentences\n",
    "        for content in contents:\n",
    "            sequences.append(list(map(lambda x: str(x), list(nlp(content).sents))))\n",
    "\n",
    "    return sequences\n",
    "\n",
    "\n",
    "for mode in modes:\n",
    "    print(mode)\n",
    "    post_sequences = get_sequences(post_contents, mode[0])\n",
    "    comment_sequences = get_sequences(comment_bodies, mode[1])\n",
    "    reply_sequences = get_sequences(reply_contents, mode[2])\n",
    "\n",
    "    data = []\n",
    "    max_post, max_comment, max_reply = 0, 0, 0\n",
    "    i = 0\n",
    "    for post, comment, reply, satisfaction, satisfaction_float in zip(post_sequences, comment_sequences,\n",
    "                                                                          reply_sequences, satisfactions,\n",
    "                                                                          satisfactions_float):\n",
    "        if len(post) > max_post:\n",
    "            max_post = len(post)\n",
    "        if len(comment) > max_comment:\n",
    "            max_comment = len(comment)\n",
    "        if len(reply) > max_reply:\n",
    "            max_reply = len(reply)\n",
    "\n",
    "        data.append([i, post, comment, reply, satisfaction, satisfaction_float])\n",
    "        i += 1\n",
    "\n",
    "    print(max_post, max_comment, max_reply)\n",
    "    max_count = max(max_post, max_comment, max_reply)\n",
    "    print(max_count)\n",
    "\n",
    "    columns = ['index', 'post_contents', 'comment_contents', 'reply_contents', 'label', 'score']\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    # data split (train & test sets)\n",
    "    idx_train, idx_remain = train_test_split(df.index.values, test_size=0.20, random_state=42)\n",
    "    idx_val, idx_test = train_test_split(idx_remain, test_size=0.50, random_state=42)\n",
    "\n",
    "    train_df = df.iloc[idx_train]\n",
    "    val_df = df.iloc[idx_val]\n",
    "    test_df = df.iloc[idx_test]\n",
    "\n",
    "    count_min_label = min(train_df['label'].value_counts())\n",
    "\n",
    "    labels = [0, 1, 2]\n",
    "\n",
    "    train_sample_df = pd.DataFrame([], columns=columns)\n",
    "\n",
    "    for label in labels:\n",
    "        tmp = train_df[train_df['label'] == label]\n",
    "        tmp_sampled = tmp.sample(frac=1).iloc[:count_min_label]\n",
    "        train_sample_df = pd.concat([train_sample_df, tmp_sampled])\n",
    "\n",
    "    train_sample_df = train_sample_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e0bf40",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637e711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tensor(data):\n",
    "    return (data - torch.min(data)) / (torch.max(data) - torch.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e805e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_func_ig(inputs, p_count, c_count, model, softmax=False):\n",
    "    embeddings = inputs[0]\n",
    "    \n",
    "    for i, now_max, now_count in zip(range(2), [model.max_post_len, model.max_comment_len], [p_count, c_count]):\n",
    "        now_embeddings = embeddings.swapaxes(0, 1)\n",
    "        if i == 0:\n",
    "            now_embeddings = model.pe(now_embeddings[:model.max_post_len])\n",
    "        else:\n",
    "            now_embeddings = model.pe(now_embeddings[model.max_post_len:])\n",
    "            \n",
    "        # make masks\n",
    "        src_mask, src_key_padding_mask = make_masks(now_max, now_count, model.device)\n",
    "        \n",
    "        encoder_output = model.encoder(now_embeddings, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        encoder_output = torch.mean(encoder_output[:now_count], dim=0).squeeze(0)\n",
    "        \n",
    "        if i == 0:\n",
    "            total_encoder_output = encoder_output\n",
    "        else:\n",
    "            total_encoder_output = torch.cat([total_encoder_output, encoder_output])\n",
    "    \n",
    "    encoder_outputs = total_encoder_output.unsqueeze(0)\n",
    "    encoder_outputs = model.classifier1(encoder_outputs)\n",
    "    encoder_outputs = torch.cat([encoder_outputs, torch.zeros(1, model.embedding_size, device=model.device)], dim=1)\n",
    "\n",
    "    # mean + flatten attentioned tensor\n",
    "    batch_embeddings_list = []\n",
    "    outputs_list = []\n",
    "    attentions = []\n",
    "    \n",
    "    batch_embeddings = inputs.clone().detach()\n",
    "\n",
    "    for i in range(len(batch_embeddings)):\n",
    "        non_zero_rows = batch_embeddings[i][0][batch_embeddings[i][0].sum(dim=1) != 0]\n",
    "        zero_rows = torch.zeros((batch_embeddings[i][0].shape[0] - non_zero_rows.shape[0], model.embedding_size),\n",
    "                                dtype=torch.int, device=model.device)\n",
    "        batch_embeddings[i] = torch.cat([non_zero_rows, zero_rows])\n",
    "\n",
    "    embeddings = batch_embeddings[0].swapaxes(0, 1)\n",
    "    src_mask, src_key_padding_mask = make_masks(model.max_post_len, [p_count, c_count], model.device,\n",
    "                                                model.max_post_len, model.max_comment_len, \"concat_all\")\n",
    "\n",
    "    encoder_output = model.encoder(embeddings, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "    attention = model.encoder_layer.self_attn(encoder_output, encoder_output, encoder_output,\n",
    "                                              attn_mask=src_mask, key_padding_mask=src_key_padding_mask)[0]\n",
    "\n",
    "    if model.attention_mode == 'attention_residual':\n",
    "        # add & norm\n",
    "        residual = outputs_list[i]\n",
    "        attention = self.dropout(attention) + residual\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "    # mul mask - diagonal masking\n",
    "    attention = attention.swapaxes(0, 2)\n",
    "    mask = torch.tensor([1] * (p_count + c_count) + [0] * (model.max_post_len + model.max_comment_len - (p_count + c_count))).to(model.device)\n",
    "    attention = attention.mul(mask).swapaxes(0, 2)\n",
    "\n",
    "    attention = torch.flatten(attention)\n",
    "    attention = model.attn_classifier1(attention)\n",
    "    attention = model.attn_classifier2(attention)\n",
    "    encoder_outputs[i][model.embedding_size:] = attention\n",
    "    encoder_outputs = model.mean_attn_layer(encoder_outputs)\n",
    "    logits = model.classifier2(encoder_outputs)\n",
    "    \n",
    "    if softmax:\n",
    "        logits = F.softmax(logits, dim=1)\n",
    "    \n",
    "    return logits\n",
    "\n",
    "\n",
    "ig = IntegratedGradients(forward_func_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ede48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(target, path, epoch, softmax):\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    \n",
    "    model_path = f'{path}/epoch_{epoch}.model'\n",
    "\n",
    "    if softmax:\n",
    "        model = SplitBertConcatEncoderModel(num_labels=len(labels), embedding_size=384, max_len=max_count, \n",
    "                                            max_post_len=max_post, max_comment_len=max_comment,\n",
    "                                            device='cpu', target=target, concat_mode=\"sep_attention\",\n",
    "                                           attention_mode=False, output_attentions=True, softmax=True)\n",
    "    else:\n",
    "        model = SplitBertConcatEncoderModel(num_labels=len(labels), embedding_size=384, max_len=max_count, \n",
    "                                            max_post_len=max_post, max_comment_len=max_comment,\n",
    "                                            device='cpu', target=target, concat_mode=\"sep_attention\",\n",
    "                                           attention_mode=False, output_attentions=True)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to('cpu')\n",
    "    model.eval()\n",
    "\n",
    "    for param in model.sbert.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    for param in model.bert.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    return device, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f529f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_ref_pair(targets):\n",
    "    input_ids_list, ref_input_ids_list, attention_masks_list, sentence_count_list = [], [], [], []\n",
    "    \n",
    "    for contents in targets:\n",
    "        result = tokenizer(contents, pad_to_max_length=True, truncation=True, max_length=256, return_tensors='pt')\n",
    "        \n",
    "        input_ids = result['input_ids']\n",
    "        sentence_count_list.append(torch.tensor(len(input_ids)).unsqueeze(0))\n",
    "        attention_masks = result['attention_mask']\n",
    "        \n",
    "        pad = (0, 0, 0, max_count-len(input_ids))\n",
    "        input_ids = nn.functional.pad(input_ids, pad, \"constant\", 0)\n",
    "        attention_masks = nn.functional.pad(attention_masks, pad, \"constant\", 0)\n",
    "        ref_input_ids = torch.zeros_like(input_ids)\n",
    "\n",
    "        input_ids_list.append(input_ids.unsqueeze(0))\n",
    "        ref_input_ids_list.append(ref_input_ids.unsqueeze(0))\n",
    "        attention_masks_list.append(attention_masks.unsqueeze(0))\n",
    "    \n",
    "    return input_ids_list, ref_input_ids_list, attention_masks_list, sentence_count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f2e6dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attributions(attribution):\n",
    "    attributions = attribution.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d435e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexes(filename):\n",
    "    index_df = pd.read_csv(filename, encoding='UTF-8')\n",
    "    index_df.columns = ['Unnamed: 0', 'prediction', 'label', 'score', 'idx']\n",
    "    val_index = sorted(list(index_df.idx.values))\n",
    "    \n",
    "    return val_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7735b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = get_indexes(f'../predicting-satisfaction-using-graphs/csv/splitbert_classifier/post_comment/seg_seg/epoch_4_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39c6191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitbert_integrated_gradient_post_comment(index, post, comment, p_sentences, c_sentences, label, score, visualize=False, softmax=False):\n",
    "    \n",
    "    def post_or_comment_or_reply(index):\n",
    "        for i, sentences in enumerate(all_sentences):\n",
    "            if all_tokens[index] in sentences:\n",
    "                if i == 0:\n",
    "                    return 'post'\n",
    "                elif i == 1:\n",
    "                    return 'comment'\n",
    "                else:\n",
    "                    return 'reply'\n",
    "    \n",
    "    input_ids, ref_input_ids, attention_masks, sentence_counts = construct_input_ref_pair([post, comment])\n",
    "    \n",
    "    one_hot_labels = torch.nn.functional.one_hot(torch.tensor(label), num_classes=len(labels))\n",
    "    inputs = {'labels': one_hot_labels.type(torch.float).to(device),\n",
    "          'input_ids1': input_ids[0].to(device),\n",
    "          'input_ids2': input_ids[1].to(device),\n",
    "          'attention_mask1': attention_masks[0].to(device),\n",
    "          'attention_mask2': attention_masks[1].to(device),\n",
    "          'sentence_count1': sentence_counts[0].to(device),\n",
    "          'sentence_count2': sentence_counts[1].to(device),\n",
    "          'mode': 'post_comment'\n",
    "         }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        inputs = pc_model(**inputs).hidden_states\n",
    "\n",
    "    # inputs = torch.stack(embeddings, dim=0)\n",
    "    pred = forward_func_ig(inputs, sentence_counts[0], sentence_counts[1], pc_model)\n",
    "    # print(f'answer: {label}, predict: {torch.argmax(pred)}')\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    attribution, delta = ig.attribute(inputs=inputs, target=torch.argmax(pred), additional_forward_args=(sentence_counts[0], sentence_counts[1], pc_model, softmax), n_steps=1, return_convergence_delta=True)\n",
    "    attributions = summarize_attributions(attribution)\n",
    "    f_attributions = torch.flatten(attributions)\n",
    "    f_attributions = f_attributions[f_attributions.nonzero()].squeeze(1)\n",
    "    abs_attributions = list(map(abs, map(float, f_attributions)))\n",
    "    idx_attributions = []\n",
    "    for j in range(len(abs_attributions)):\n",
    "        idx_attributions.append((j, abs_attributions[j], f_attributions[j].item()))\n",
    "    idx_attributions.sort(key=lambda x:x[1], reverse=True)\n",
    "        \n",
    "    top3 = idx_attributions[:3]\n",
    "    \n",
    "    if visualize:\n",
    "        all_sentences = [['[[post]]'], post, ['[[comment]]'], comment]\n",
    "        all_tokens = [item for all_sentences in all_sentences for item in all_sentences]\n",
    "        \n",
    "        vis_attributions = []\n",
    "        \n",
    "        j = 0\n",
    "        for i in range(len(all_tokens)):\n",
    "            if all_tokens[i] in ['[[post]]', '[[comment]]']:\n",
    "                vis_attributions.append(0)\n",
    "            else:\n",
    "                vis_attributions.append(f_attributions[j].item())\n",
    "                j += 1\n",
    "                \n",
    "        vis_attributions = torch.tensor(vis_attributions)\n",
    "        \n",
    "        score_vis = viz.VisualizationDataRecord(vis_attributions,\n",
    "                                                torch.max(torch.softmax(pred, dim=0)),\n",
    "                                                torch.argmax(pred),  # predicted label\n",
    "                                                f'{label}, {score}',  # true label\n",
    "                                                p_sentences + ' ' + c_sentences,\n",
    "                                                vis_attributions.sum(),\n",
    "                                                all_tokens,\n",
    "                                                delta)\n",
    "        raw_text = ' '.join(post) + ' '.join(comment)\n",
    "        \n",
    "        print('\\033[1m', 'Visualization For Score', '\\033[0m')\n",
    "        viz.visualize_text([score_vis])\n",
    "        print(vis_attributions)\n",
    "        \n",
    "    else:\n",
    "        where = []\n",
    "        \n",
    "        all_sentences = [post, comment]\n",
    "        all_tokens = [item for all_sentences in all_sentences for item in all_sentences]\n",
    "\n",
    "        for j in range(len(top3)):\n",
    "            where.append(post_or_comment_or_reply(top3[j][0]))\n",
    "            result.append([index, post, comment, score, all_tokens[top3[j][0]], top3[j][2], post_or_comment_or_reply(top3[j][0])])\n",
    "\n",
    "        # result.append([index, post, comment, score, all_tokens[top3[0][0]], top3[0][2], where[0]])\n",
    "        # result.append([index, post, comment, score, all_tokens[top3[1][0]], top3[1][2], where[1]])\n",
    "        # result.append([index, post, comment, score, all_tokens[top3[2][0]], top3[2][2], where[2]])\n",
    "\n",
    "        return result, label, torch.argmax(pred).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a64a29d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device, pc_model, tokenizer = prepare_model('post_comment', '../predicting-satisfaction-using-graphs/splitbert/model/seg_seg/w_softmax', 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "691b0f01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Visualization For Score \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mykim/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0, 2.45</b></text></td><td><text style=\"padding-right:2em\"><b>1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>Im the guy no one suspects is as messed up as I am....Am wealthy, have nice wife, kids, everyone envious of our home (8000 sf so not small in wealthiest county in the USA).....good looking and well you name it ..........But Im now unemployed, wife has and I think still sleeps with other men, am now drinking a lot, no sex in years, kids make jokes about my drinking to wife......I embarass my wife out in piblic, I dont work out anymore and have 50 lbs more than I did a yr and half ago, I am going broke and well Im a loser I think........But when i drink at least the pain and how much of a loser I am doesnt keep me awake all night and makes me feel like I can do stuff when drunk...... As bad as I feel about the depression, and I am pretty sure you are just taking out your pent up anger on him, you came out swinging first by calling him a moron over a little mistsle first</b></text></td><td><text style=\"padding-right:2em\"><b>-0.46</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [[post]]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Im the guy no one suspects is as messed up as I am....Am wealthy, have nice wife, kids, everyone envious of our home (8000 sf so not small in wealthiest county in the USA).....good looking and well you name it ..........But Im now unemployed, wife has and I think still sleeps with other men, am now drinking a lot, no sex in years, kids make jokes about my drinking to wife......I embarass my wife out in piblic, I dont work out anymore and have 50 lbs more than I did a yr and half ago, I am going broke and well Im a loser I think........But when i drink at least the pain and how much of a loser I am doesnt keep me awake all night and makes me feel like I can do stuff when drunk......                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [[comment]]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> As bad as I feel about the depression, and I am pretty sure you are just taking out your pent up anger on him, you came out swinging first by calling him a moron over a little mistsle first                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.4364,  0.0000, -0.8998])\n"
     ]
    }
   ],
   "source": [
    "for i in index_list[:1]:\n",
    "    splitbert_integrated_gradient_post_comment(i, post_sequences[i], comment_sequences[i], post_contents[i], comment_bodies[i], satisfactions[i], satisfactions_float[i], True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ebfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ffd910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213258d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83bbc882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device, pc_model, tokenizer = prepare_model('post_comment', '../predicting-satisfaction-using-graphs/splitbert/model/seg_seg/wo_softmax', 4, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d6a4b67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Visualization For Score \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0, 2.45</b></text></td><td><text style=\"padding-right:2em\"><b>0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>Im the guy no one suspects is as messed up as I am....Am wealthy, have nice wife, kids, everyone envious of our home (8000 sf so not small in wealthiest county in the USA).....good looking and well you name it ..........But Im now unemployed, wife has and I think still sleeps with other men, am now drinking a lot, no sex in years, kids make jokes about my drinking to wife......I embarass my wife out in piblic, I dont work out anymore and have 50 lbs more than I did a yr and half ago, I am going broke and well Im a loser I think........But when i drink at least the pain and how much of a loser I am doesnt keep me awake all night and makes me feel like I can do stuff when drunk...... As bad as I feel about the depression, and I am pretty sure you are just taking out your pent up anger on him, you came out swinging first by calling him a moron over a little mistsle first</b></text></td><td><text style=\"padding-right:2em\"><b>0.68</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [[post]]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Im the guy no one suspects is as messed up as I am....Am wealthy, have nice wife, kids, everyone envious of our home (8000 sf so not small in wealthiest county in the USA).....good looking and well you name it ..........But Im now unemployed, wife has and I think still sleeps with other men, am now drinking a lot, no sex in years, kids make jokes about my drinking to wife......I embarass my wife out in piblic, I dont work out anymore and have 50 lbs more than I did a yr and half ago, I am going broke and well Im a loser I think........But when i drink at least the pain and how much of a loser I am doesnt keep me awake all night and makes me feel like I can do stuff when drunk......                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [[comment]]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 53%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> As bad as I feel about the depression, and I am pretty sure you are just taking out your pent up anger on him, you came out swinging first by calling him a moron over a little mistsle first                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000, -0.2832,  0.0000,  0.9591])\n"
     ]
    }
   ],
   "source": [
    "for i in index_list[:1]:\n",
    "    splitbert_integrated_gradient_post_comment(i, post_sequences[i], comment_sequences[i], post_contents[i], comment_bodies[i], satisfactions[i], satisfactions_float[i], True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc6719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
