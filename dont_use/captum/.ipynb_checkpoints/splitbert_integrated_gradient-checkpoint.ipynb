{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8991db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 13:57:59.034937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.lang.en import English\n",
    "from splitbert.textsplit import text_segmentation\n",
    "from splitbert.splitbert import SplitBertConcatEncoderModel\n",
    "from splitbert.splitbert import conduct_input_ids_and_attention_masks\n",
    "from splitbert.splitbert import make_masks\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd1668f",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a53f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seg', 'seg', 'snt']\n",
      "10 4 10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "post_df = pd.read_csv('../predicting-satisfaction-using-graphs/csv/dataset/liwc_post.csv', encoding='UTF-8')\n",
    "comment_df = pd.read_csv('../predicting-satisfaction-using-graphs/csv/dataset/liwc_comment.csv', encoding='UTF-8')\n",
    "reply_df = pd.read_csv('../predicting-satisfaction-using-graphs/csv/dataset/avg_satisfaction_raw_0-999.csv', encoding='ISO-8859-1')\n",
    "\n",
    "modes = [['seg', 'seg', 'snt']]\n",
    "\n",
    "nlp = English()\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# satisfaction score (y)\n",
    "satisfactions_float = list(reply_df['satisfy_composite'])\n",
    "satisfactions = []\n",
    "\n",
    "for s in satisfactions_float:\n",
    "    if s < 3.5:\n",
    "        satisfactions.append(0)\n",
    "    elif s < 5:\n",
    "        satisfactions.append(1)\n",
    "    else:\n",
    "        satisfactions.append(2)\n",
    "\n",
    "reply_contents = list(reply_df['replyContent'])\n",
    "post_contents = list(post_df['content'])\n",
    "comment_bodies = list(comment_df['content'])\n",
    "\n",
    "\n",
    "def get_sequences(contents, mode):\n",
    "    sequences = []\n",
    "\n",
    "    if mode == 'all':\n",
    "        for content in contents:\n",
    "            sequences.append([content])\n",
    "    elif mode == 'seg':\n",
    "        for content in contents:\n",
    "            sentences = list(map(lambda x: str(x), list(nlp(content).sents)))\n",
    "            sequences.append(text_segmentation(sentences))\n",
    "    else:  # sentences\n",
    "        for content in contents:\n",
    "            sequences.append(list(map(lambda x: str(x), list(nlp(content).sents))))\n",
    "\n",
    "    return sequences\n",
    "\n",
    "\n",
    "for mode in modes:\n",
    "    print(mode)\n",
    "    post_sequences = get_sequences(post_contents, mode[0])\n",
    "    comment_sequences = get_sequences(comment_bodies, mode[1])\n",
    "    reply_sequences = get_sequences(reply_contents, mode[2])\n",
    "\n",
    "    data = []\n",
    "    max_post, max_comment, max_reply = 0, 0, 0\n",
    "    i = 0\n",
    "    for post, comment, reply, satisfaction, satisfaction_float in zip(post_sequences, comment_sequences,\n",
    "                                                                          reply_sequences, satisfactions,\n",
    "                                                                          satisfactions_float):\n",
    "        if len(post) > max_post:\n",
    "            max_post = len(post)\n",
    "        if len(comment) > max_comment:\n",
    "            max_comment = len(comment)\n",
    "        if len(reply) > max_reply:\n",
    "            max_reply = len(reply)\n",
    "\n",
    "        data.append([i, post, comment, reply, satisfaction, satisfaction_float])\n",
    "        i += 1\n",
    "\n",
    "    print(max_post, max_comment, max_reply)\n",
    "    max_count = max(max_post, max_comment, max_reply)\n",
    "    print(max_count)\n",
    "\n",
    "    columns = ['index', 'post_contents', 'comment_contents', 'reply_contents', 'label', 'score']\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    # data split (train & test sets)\n",
    "    idx_train, idx_remain = train_test_split(df.index.values, test_size=0.20, random_state=42)\n",
    "    idx_val, idx_test = train_test_split(idx_remain, test_size=0.50, random_state=42)\n",
    "\n",
    "    train_df = df.iloc[idx_train]\n",
    "    val_df = df.iloc[idx_val]\n",
    "    test_df = df.iloc[idx_test]\n",
    "\n",
    "    count_min_label = min(train_df['label'].value_counts())\n",
    "\n",
    "    labels = [0, 1, 2]\n",
    "\n",
    "    train_sample_df = pd.DataFrame([], columns=columns)\n",
    "\n",
    "    for label in labels:\n",
    "        tmp = train_df[train_df['label'] == label]\n",
    "        tmp_sampled = tmp.sample(frac=1).iloc[:count_min_label]\n",
    "        train_sample_df = pd.concat([train_sample_df, tmp_sampled])\n",
    "\n",
    "    train_sample_df = train_sample_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e0bf40",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f0bf5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_func_ig(inputs):\n",
    "    now = 0\n",
    "\n",
    "    for embeddings, count in zip(inputs, sentence_counts):\n",
    "        embeddings = embeddings.unsqueeze(0)\n",
    "        embeddings = embeddings.swapaxes(0, 1)\n",
    "\n",
    "        embeddings = model.pe(embeddings)\n",
    "\n",
    "        src_mask, src_key_padding_mask = make_masks(model.max_len, count, device)\n",
    "\n",
    "        encoder_output = model.encoder(embeddings, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        encoder_output = torch.mean(encoder_output[:count], dim=0)\n",
    "\n",
    "        if now == 0:\n",
    "            result_outputs = encoder_output\n",
    "        else:\n",
    "            result_outputs = torch.cat([result_outputs, encoder_output], dim=1)\n",
    "        now += 1\n",
    "    \n",
    "    outputs = model.classifier1(result_outputs)\n",
    "    logits = model.classifier2(outputs)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01f62ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_func_ig2(inputs, sentence_counts, model):\n",
    "    now = 0\n",
    "\n",
    "    for encoder_output, count in zip(inputs, sentence_counts):\n",
    "        encoder_output = encoder_output.swapaxes(0, 1)\n",
    "        encoder_output = torch.mean(encoder_output[:count], dim=0)\n",
    "\n",
    "        if now == 0:\n",
    "            result_outputs = encoder_output\n",
    "        else:\n",
    "            result_outputs = torch.cat([result_outputs, encoder_output], dim=1)\n",
    "        now += 1\n",
    "        \n",
    "    outputs = model.classifier1(result_outputs)\n",
    "    logits = model.classifier2(outputs)\n",
    "    return logits\n",
    "\n",
    "ig = IntegratedGradients(forward_func_ig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ede48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(target, mode, epoch):\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "    model_path = f'../predicting-satisfaction-using-graphs/splitbert/model/{mode}/epoch_{epoch}.model'\n",
    "    model = SplitBertConcatEncoderModel(num_labels=len(labels), embedding_size=384, max_len=max_count, device='cpu', target=target)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to('cpu')\n",
    "    model.eval()\n",
    "\n",
    "    for param in model.sbert.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    for param in model.bert.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    return device, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a64a29d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device, pc_model, tokenizer = prepare_model('post_comment', 'seg_seg', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68a56f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device, t_model, tokenizer = prepare_model('triplet', 'seg_seg_snt', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f529f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_ref_pair(targets):\n",
    "    input_ids_list, ref_input_ids_list, attention_masks_list, sentence_count_list = [], [], [], []\n",
    "    \n",
    "    for contents in targets:\n",
    "        result = tokenizer(contents, pad_to_max_length=True, truncation=True, max_length=256, return_tensors='pt')\n",
    "        \n",
    "        input_ids = result['input_ids']\n",
    "        sentence_count_list.append(torch.tensor(len(input_ids)).unsqueeze(0))\n",
    "        attention_masks = result['attention_mask']\n",
    "        \n",
    "        pad = (0, 0, 0, max_count-len(input_ids))\n",
    "        input_ids = nn.functional.pad(input_ids, pad, \"constant\", 0)\n",
    "        attention_masks = nn.functional.pad(attention_masks, pad, \"constant\", 0)\n",
    "        ref_input_ids = torch.zeros_like(input_ids)\n",
    "\n",
    "        input_ids_list.append(input_ids.unsqueeze(0))\n",
    "        ref_input_ids_list.append(ref_input_ids.unsqueeze(0))\n",
    "        attention_masks_list.append(attention_masks.unsqueeze(0))\n",
    "    \n",
    "    return input_ids_list, ref_input_ids_list, attention_masks_list, sentence_count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f2e6dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attributions(attribution):\n",
    "    attributions = attribution.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8f207a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitbert_integrated_gradient_triplet(index, post, comment, reply, p_sentences, c_sentences, r_sentences, label, score, visualize=False):\n",
    "    \n",
    "    def post_or_comment_or_reply(index):\n",
    "        for i, sentences in enumerate(all_sentences):\n",
    "            if all_tokens[index] in sentences:\n",
    "                if i == 0:\n",
    "                    return 'post'\n",
    "                elif i == 1:\n",
    "                    return 'comment'\n",
    "                else:\n",
    "                    return 'reply'\n",
    "    \n",
    "    input_ids, ref_input_ids, attention_masks, sentence_counts = construct_input_ref_pair([post, comment, reply])\n",
    "    \n",
    "    one_hot_labels = torch.nn.functional.one_hot(torch.tensor(label), num_classes=len(labels))\n",
    "    inputs = {'labels': one_hot_labels.type(torch.float).to(device),\n",
    "          'input_ids1': input_ids[0].to(device),\n",
    "          'input_ids2': input_ids[1].to(device),\n",
    "          'input_ids3': input_ids[2].to(device),\n",
    "          'attention_mask1': attention_masks[0].to(device),\n",
    "          'attention_mask2': attention_masks[1].to(device),\n",
    "          'attention_mask3': attention_masks[2].to(device),\n",
    "          'sentence_count1': sentence_counts[0].to(device),\n",
    "          'sentence_count2': sentence_counts[1].to(device),\n",
    "          'sentence_count3': sentence_counts[2].to(device),\n",
    "          'mode': 'triplet'\n",
    "         }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embeddings = t_model(**inputs).hidden_states\n",
    "        \n",
    "    inputs = torch.stack(embeddings, dim=0)\n",
    "    pred = forward_func_ig2(inputs, sentence_counts, t_model)\n",
    "    # print(f'answer: {label}, predict: {torch.argmax(pred)}')\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    attribution, delta = ig.attribute(inputs=inputs, target=torch.argmax(pred), additional_forward_args=(sentence_counts, t_model), return_convergence_delta=True)\n",
    "    attributions = summarize_attributions(attribution)\n",
    "    f_attributions = torch.flatten(attributions)\n",
    "    f_attributions = f_attributions[f_attributions.nonzero()].squeeze(1)\n",
    "    abs_attributions = list(map(abs, map(float, f_attributions)))\n",
    "    idx_attributions = []\n",
    "    for j in range(len(abs_attributions)):\n",
    "        idx_attributions.append((j, abs_attributions[j], f_attributions[j].item()))\n",
    "    idx_attributions.sort(key=lambda x:x[1], reverse=True)\n",
    "        \n",
    "    top3 = idx_attributions[:3]\n",
    "    \n",
    "    if visualize:\n",
    "        all_sentences = [['[[post]]'], post, ['[[comment]]'], comment, ['[[reply]]'], reply]\n",
    "        all_tokens = [item for all_sentences in all_sentences for item in all_sentences]\n",
    "        \n",
    "        vis_attributions = []\n",
    "        \n",
    "        j = 0\n",
    "        for i in range(len(all_tokens)):\n",
    "            if all_tokens[i] in ['[[post]]', '[[comment]]', '[[reply]]']:\n",
    "                vis_attributions.append(0)\n",
    "            else:\n",
    "                vis_attributions.append(f_attributions[j].item())\n",
    "                j += 1\n",
    "                \n",
    "        vis_attributions = torch.tensor(vis_attributions)\n",
    "        \n",
    "        score_vis = viz.VisualizationDataRecord(vis_attributions,\n",
    "                                                torch.max(torch.softmax(pred, dim=0)),\n",
    "                                                torch.argmax(pred),  # predicted label\n",
    "                                                f'{label}, {score}',  # true label\n",
    "                                                p_sentences + ' ' + c_sentences + ' ' + r_sentences,\n",
    "                                                vis_attributions.sum(),\n",
    "                                                all_tokens,\n",
    "                                                delta)\n",
    "        raw_text = ' '.join(post) + ' '.join(comment) + ' '.join(reply)\n",
    "        print('\\033[1m', 'Visualization For Score', '\\033[0m')\n",
    "        viz.visualize_text([score_vis])\n",
    "        print(vis_attributions)\n",
    "        \n",
    "    else:\n",
    "        where = []\n",
    "        \n",
    "        all_sentences = [post, comment, reply]\n",
    "        all_tokens = [item for all_sentences in all_sentences for item in all_sentences]\n",
    "\n",
    "        for j in range(len(top3)):\n",
    "            where.append(post_or_comment_or_reply(top3[j][0]))\n",
    "\n",
    "        result.append([index, post, comment, reply, score, all_tokens[top3[0][0]], top3[0][2], where[0]])\n",
    "        result.append([index, post, comment, reply, score, all_tokens[top3[1][0]], top3[1][2], where[1]])\n",
    "        result.append([index, post, comment, reply, score, all_tokens[top3[2][0]], top3[2][2], where[2]])\n",
    "\n",
    "        return result, label, torch.argmax(pred).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39c6191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitbert_integrated_gradient_post_comment(index, post, comment, p_sentences, c_sentences, label, score, visualize=False):\n",
    "    \n",
    "    def post_or_comment_or_reply(index):\n",
    "        for i, sentences in enumerate(all_sentences):\n",
    "            if all_tokens[index] in sentences:\n",
    "                if i == 0:\n",
    "                    return 'post'\n",
    "                elif i == 1:\n",
    "                    return 'comment'\n",
    "                else:\n",
    "                    return 'reply'\n",
    "    \n",
    "    input_ids, ref_input_ids, attention_masks, sentence_counts = construct_input_ref_pair([post, comment])\n",
    "    \n",
    "    one_hot_labels = torch.nn.functional.one_hot(torch.tensor(label), num_classes=len(labels))\n",
    "    inputs = {'labels': one_hot_labels.type(torch.float).to(device),\n",
    "          'input_ids1': input_ids[0].to(device),\n",
    "          'input_ids2': input_ids[1].to(device),\n",
    "          'attention_mask1': attention_masks[0].to(device),\n",
    "          'attention_mask2': attention_masks[1].to(device),\n",
    "          'sentence_count1': sentence_counts[0].to(device),\n",
    "          'sentence_count2': sentence_counts[1].to(device),\n",
    "          'mode': 'post_comment'\n",
    "         }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embeddings = pc_model(**inputs).hidden_states\n",
    "        \n",
    "    inputs = torch.stack(embeddings, dim=0)\n",
    "    pred = forward_func_ig2(inputs, sentence_counts, pc_model)\n",
    "    # print(f'answer: {label}, predict: {torch.argmax(pred)}')\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    attribution, delta = ig.attribute(inputs=inputs, target=torch.argmax(pred), additional_forward_args=(sentence_counts, pc_model), return_convergence_delta=True)\n",
    "    attributions = summarize_attributions(attribution)\n",
    "    f_attributions = torch.flatten(attributions)\n",
    "    f_attributions = f_attributions[f_attributions.nonzero()].squeeze(1)\n",
    "    abs_attributions = list(map(abs, map(float, f_attributions)))\n",
    "    idx_attributions = []\n",
    "    for j in range(len(abs_attributions)):\n",
    "        idx_attributions.append((j, abs_attributions[j], f_attributions[j].item()))\n",
    "    idx_attributions.sort(key=lambda x:x[1], reverse=True)\n",
    "        \n",
    "    top3 = idx_attributions[:3]\n",
    "    \n",
    "    if visualize:\n",
    "        all_sentences = [['[[post]]'], post, ['[[comment]]'], comment]\n",
    "        all_tokens = [item for all_sentences in all_sentences for item in all_sentences]\n",
    "        \n",
    "        vis_attributions = []\n",
    "        \n",
    "        j = 0\n",
    "        for i in range(len(all_tokens)):\n",
    "            if all_tokens[i] in ['[[post]]', '[[comment]]']:\n",
    "                vis_attributions.append(0)\n",
    "            else:\n",
    "                vis_attributions.append(f_attributions[j].item())\n",
    "                j += 1\n",
    "                \n",
    "        vis_attributions = torch.tensor(vis_attributions)\n",
    "        \n",
    "        score_vis = viz.VisualizationDataRecord(vis_attributions,\n",
    "                                                torch.max(torch.softmax(pred, dim=0)),\n",
    "                                                torch.argmax(pred),  # predicted label\n",
    "                                                f'{label}, {score}',  # true label\n",
    "                                                p_sentences + ' ' + c_sentences,\n",
    "                                                vis_attributions.sum(),\n",
    "                                                all_tokens,\n",
    "                                                delta)\n",
    "        raw_text = ' '.join(post) + ' '.join(comment)\n",
    "        \n",
    "        print('\\033[1m', 'Visualization For Score', '\\033[0m')\n",
    "        viz.visualize_text([score_vis])\n",
    "        print(vis_attributions)\n",
    "        \n",
    "    else:\n",
    "        where = []\n",
    "        \n",
    "        all_sentences = [post, comment]\n",
    "        all_tokens = [item for all_sentences in all_sentences for item in all_sentences]\n",
    "\n",
    "        for j in range(len(top3)):\n",
    "            where.append(post_or_comment_or_reply(top3[j][0]))\n",
    "            result.append([index, post, comment, score, all_tokens[top3[j][0]], top3[j][2], post_or_comment_or_reply(top3[j][0])])\n",
    "\n",
    "        # result.append([index, post, comment, score, all_tokens[top3[0][0]], top3[0][2], where[0]])\n",
    "        # result.append([index, post, comment, score, all_tokens[top3[1][0]], top3[1][2], where[1]])\n",
    "        # result.append([index, post, comment, score, all_tokens[top3[2][0]], top3[2][2], where[2]])\n",
    "\n",
    "        return result, label, torch.argmax(pred).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d435e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexes(filename):\n",
    "    index_df = pd.read_csv(filename, encoding='UTF-8')\n",
    "    index_df.columns = ['Unnamed: 0', 'prediction', 'label', 'score', 'idx']\n",
    "    val_index = sorted(list(index_df.idx.values))\n",
    "    \n",
    "    return val_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f52b1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_index = get_indexes(f'../predicting-satisfaction-using-graphs/csv/splitbert_classifier/post_comment/seg_seg/epoch_4_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6178ec7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(val_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2e161b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_main(index_filename):\n",
    "    index_list = get_indexes(index_filename)\n",
    "    result_list = []\n",
    "    label_pred_list = []\n",
    "    \n",
    "    for i in index_list:\n",
    "        result, label, pred = splitbert_integrated_gradient_triplet(i, post_sequences[i], comment_sequences[i], reply_sequences[i], post_contents[i], comment_bodies[i], reply_contents[i], satisfactions[i], satisfactions_float[i])\n",
    "        result_list.extend(result)\n",
    "        \n",
    "        for i in range(3):\n",
    "            label_pred_list.append((label, pred))\n",
    "        \n",
    "    return result_list, label_pred_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5564d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_comment_main(index_filename):\n",
    "    index_list = get_indexes(index_filename)\n",
    "    result_list = []\n",
    "    label_pred_list = []\n",
    "    \n",
    "    for i in index_list:\n",
    "        result, label, pred = splitbert_integrated_gradient_post_comment(i, post_sequences[i], comment_sequences[i], post_contents[i], comment_bodies[i], satisfactions[i], satisfactions_float[i])\n",
    "        result_list.extend(result)\n",
    "        \n",
    "        for i in range(len(result)):\n",
    "            label_pred_list.append((label, pred))\n",
    "        \n",
    "    return result_list, label_pred_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a47b2e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271 271\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filtered = True\n",
    "    \n",
    "    # result_list, label_pred_list = main(val_index)\n",
    "    result_list, label_pred_list = post_comment_main(val_index)\n",
    "    print(len(result_list), len(label_pred_list))\n",
    "    \n",
    "    if filtered:\n",
    "        filtered_list = []\n",
    "        filtered_lp_list = []\n",
    "        for result, lp in zip(result_list, label_pred_list):\n",
    "            if abs(result[5]) >= 0.5:\n",
    "                filtered_list.append(result)\n",
    "                filtered_lp_list.append(lp)\n",
    "    \n",
    "    path = '../predicting-satisfaction-using-graphs/csv/integrated_gradient_result/post_comment/'\n",
    "    columns = ['idx', 'post_text', 'comment_text', 'score', 'attr_sentence', 'attr_score', 'origin']\n",
    "    \n",
    "    def make_csv(target_list, label_pred_list):\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                result = []\n",
    "                for k in range(len(target_list)):\n",
    "                    if label_pred_list[k] == (i, j):\n",
    "                        result.append(target_list[k])\n",
    "                result_df = pd.DataFrame(result, columns=columns)\n",
    "                \n",
    "                if filtered:\n",
    "                    filename = f'label_{i}_pred_{j}_attribution_filtered.csv'\n",
    "                else:\n",
    "                    filename = f'label_{i}_pred_{j}_attribution.csv'\n",
    "                \n",
    "                result_df.to_csv(path + filename)\n",
    "    \n",
    "    \n",
    "    if not filtered:\n",
    "        make_csv(result_list, label_pred_list)\n",
    "    else:\n",
    "        make_csv(filtered_list, filtered_lp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ecc5e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 300\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filtered = True\n",
    "    \n",
    "    # result_list, label_pred_list = main(val_index)\n",
    "    result_list, label_pred_list = triplet_main(f'../predicting-satisfaction-using-graphs/csv/splitbert_classifier/triplet/seg_seg_snt/epoch_7_result.csv')\n",
    "    print(len(result_list), len(label_pred_list))\n",
    "    \n",
    "    if filtered:\n",
    "        filtered_list = []\n",
    "        filtered_lp_list = []\n",
    "        for result, lp in zip(result_list, label_pred_list):\n",
    "            if abs(result[6]) >= 0.5:\n",
    "                filtered_list.append(result)\n",
    "                filtered_lp_list.append(lp)\n",
    "    \n",
    "    path = '../predicting-satisfaction-using-graphs/csv/integrated_gradient_result/triplet/'\n",
    "    columns = ['idx', 'post_text', 'comment_text', 'reply_text', 'score', 'attr_sentence', 'attr_score', 'origin']\n",
    "    \n",
    "    def make_csv(target_list, label_pred_list):\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                result = []\n",
    "                for k in range(len(target_list)):\n",
    "                    if label_pred_list[k] == (i, j):\n",
    "                        result.append(target_list[k])\n",
    "                result_df = pd.DataFrame(result, columns=columns)\n",
    "                \n",
    "                if filtered:\n",
    "                    filename = f'label_{i}_pred_{j}_attribution_filtered.csv'\n",
    "                else:\n",
    "                    filename = f'label_{i}_pred_{j}_attribution.csv'\n",
    "                \n",
    "                result_df.to_csv(path + filename)\n",
    "    \n",
    "    \n",
    "    if not filtered:\n",
    "        make_csv(result_list, label_pred_list)\n",
    "    else:\n",
    "        make_csv(filtered_list, filtered_lp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68df90a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a43c601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 0, pred: 0\n",
      "comment    10\n",
      "post        7\n",
      "Name: origin, dtype: int64\n",
      "\n",
      "label: 0, pred: 1\n",
      "comment    3\n",
      "post       1\n",
      "Name: origin, dtype: int64\n",
      "\n",
      "label: 0, pred: 2\n",
      "comment    3\n",
      "post       2\n",
      "Name: origin, dtype: int64\n",
      "\n",
      "label: 1, pred: 0\n",
      "post       12\n",
      "comment     7\n",
      "Name: origin, dtype: int64\n",
      "\n",
      "label: 1, pred: 1\n",
      "comment    14\n",
      "post        8\n",
      "Name: origin, dtype: int64\n",
      "\n",
      "label: 1, pred: 2\n",
      "comment    15\n",
      "post        9\n",
      "Name: origin, dtype: int64\n",
      "\n",
      "label: 2, pred: 0\n",
      "comment    5\n",
      "post       4\n",
      "Name: origin, dtype: int64\n",
      "\n",
      "label: 2, pred: 1\n",
      "comment    10\n",
      "post        4\n",
      "Name: origin, dtype: int64\n",
      "\n",
      "label: 2, pred: 2\n",
      "comment    15\n",
      "post        7\n",
      "Name: origin, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index_list = []\n",
    "target = 'post_comment'\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        print(f'label: {i}, pred: {j}')\n",
    "        \n",
    "        result_df = pd.read_csv(f'../predicting-satisfaction-using-graphs/csv/integrated_gradient_result/{target}/label_{i}_pred_{j}_attribution_filtered.csv', encoding='UTF-8')\n",
    "        print(result_df.origin.value_counts())\n",
    "        \n",
    "        if i == j:\n",
    "            index_list.append(set(list(result_df.idx.values)))\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb2d686c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Visualization For Score \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0, 2.45</b></text></td><td><text style=\"padding-right:2em\"><b>0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>Im the guy no one suspects is as messed up as I am....Am wealthy, have nice wife, kids, everyone envious of our home (8000 sf so not small in wealthiest county in the USA).....good looking and well you name it ..........But Im now unemployed, wife has and I think still sleeps with other men, am now drinking a lot, no sex in years, kids make jokes about my drinking to wife......I embarass my wife out in piblic, I dont work out anymore and have 50 lbs more than I did a yr and half ago, I am going broke and well Im a loser I think........But when i drink at least the pain and how much of a loser I am doesnt keep me awake all night and makes me feel like I can do stuff when drunk...... As bad as I feel about the depression, and I am pretty sure you are just taking out your pent up anger on him, you came out swinging first by calling him a moron over a little mistsle first no he came out swinging first, he has had and still has option of deleting..but he said I was wrong when he was wrong, thats super annoying and whats wrong with this world, nobody cares what they say, he could apologize, delete or say he was wrong but did none of those 3 so no, Im not gonna relent when i was right and had no reason to read his comments since they were irrelevant.</b></text></td><td><text style=\"padding-right:2em\"><b>1.12</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [[post]]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Im the guy no one suspects is as messed up as I am....Am wealthy, have nice wife, kids, everyone envious of our home (8000 sf so not small in wealthiest county in the USA).....good looking and well you name it ..........But Im now unemployed, wife has and I think still sleeps with other men, am now drinking a lot, no sex in years, kids make jokes about my drinking to wife......I embarass my wife out in piblic, I dont work out anymore and have 50 lbs more than I did a yr and half ago, I am going broke and well Im a loser I think........But when i drink at least the pain and how much of a loser I am doesnt keep me awake all night and makes me feel like I can do stuff when drunk......                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [[comment]]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> As bad as I feel about the depression, and I am pretty sure you are just taking out your pent up anger on him, you came out swinging first by calling him a moron over a little mistsle first                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [[reply]]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 62%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> no he came out swinging first, he has had and still has option of deleting..but he said I was wrong when he was wrong, thats super annoying and whats wrong with this world, nobody cares what they say, he could apologize, delete or say he was wrong but did none of those 3 so no, Im not gonna relent when i was right and had no reason to read his comments since they were irrelevant.                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000, -0.2412,  0.0000,  0.5846,  0.0000,  0.7746])\n",
      "\u001b[1m Visualization For Score \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0, 2.45</b></text></td><td><text style=\"padding-right:2em\"><b>0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>Im the guy no one suspects is as messed up as I am....Am wealthy, have nice wife, kids, everyone envious of our home (8000 sf so not small in wealthiest county in the USA).....good looking and well you name it ..........But Im now unemployed, wife has and I think still sleeps with other men, am now drinking a lot, no sex in years, kids make jokes about my drinking to wife......I embarass my wife out in piblic, I dont work out anymore and have 50 lbs more than I did a yr and half ago, I am going broke and well Im a loser I think........But when i drink at least the pain and how much of a loser I am doesnt keep me awake all night and makes me feel like I can do stuff when drunk...... As bad as I feel about the depression, and I am pretty sure you are just taking out your pent up anger on him, you came out swinging first by calling him a moron over a little mistsle first</b></text></td><td><text style=\"padding-right:2em\"><b>0.58</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [[post]]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Im the guy no one suspects is as messed up as I am....Am wealthy, have nice wife, kids, everyone envious of our home (8000 sf so not small in wealthiest county in the USA).....good looking and well you name it ..........But Im now unemployed, wife has and I think still sleeps with other men, am now drinking a lot, no sex in years, kids make jokes about my drinking to wife......I embarass my wife out in piblic, I dont work out anymore and have 50 lbs more than I did a yr and half ago, I am going broke and well Im a loser I think........But when i drink at least the pain and how much of a loser I am doesnt keep me awake all night and makes me feel like I can do stuff when drunk......                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [[comment]]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 54%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> As bad as I feel about the depression, and I am pretty sure you are just taking out your pent up anger on him, you came out swinging first by calling him a moron over a little mistsle first                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000, -0.3517,  0.0000,  0.9361])\n"
     ]
    }
   ],
   "source": [
    "index_list = get_indexes(f'../predicting-satisfaction-using-graphs/csv/splitbert_classifier/triplet/seg_seg_snt/epoch_2_result.csv')\n",
    "for i in index_list[:1]:\n",
    "    splitbert_integrated_gradient_triplet(i, post_sequences[i], comment_sequences[i], reply_sequences[i], post_contents[i], comment_bodies[i], reply_contents[i], satisfactions[i], satisfactions_float[i], True)\n",
    "    splitbert_integrated_gradient_post_comment(i, post_sequences[i], comment_sequences[i], post_contents[i], comment_bodies[i], satisfactions[i], satisfactions_float[i], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017b41f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index, post, comment, p_sentences, c_sentences, label, score, visualize=False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
