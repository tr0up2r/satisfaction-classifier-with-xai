{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dea892ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "    r\"\"\"\n",
    "    Example toy model from the original paper (page 10)\n",
    "\n",
    "    https://arxiv.org/pdf/1703.01365.pdf\n",
    "\n",
    "\n",
    "    f(x1, x2) = RELU(ReLU(x1) - 1 - ReLU(x2))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_layer = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        print(input1)\n",
    "        print(input2)\n",
    "        relu_out1 = F.relu(input1)\n",
    "        relu_out2 = F.relu(input2)\n",
    "        print(F.relu(relu_out1 - 1 - relu_out2).shape)\n",
    "        return F.relu(relu_out1 - 1 - relu_out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c760b04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7004e-03, 8.9520e-03, 2.1969e-02, 4.0703e-02, 6.5084e-02, 9.5015e-02,\n",
      "        1.3038e-01, 1.7105e-01, 2.1686e-01, 2.6763e-01, 3.2317e-01, 3.8326e-01,\n",
      "        4.4767e-01, 5.1616e-01, 5.8845e-01, 6.6426e-01, 7.4331e-01, 8.2529e-01,\n",
      "        9.0988e-01, 9.9675e-01, 1.0856e+00, 1.1760e+00, 1.2677e+00, 1.3602e+00,\n",
      "        1.4534e+00, 1.5466e+00, 1.6398e+00, 1.7323e+00, 1.8240e+00, 1.9144e+00,\n",
      "        2.0033e+00, 2.0901e+00, 2.1747e+00, 2.2567e+00, 2.3357e+00, 2.4116e+00,\n",
      "        2.4838e+00, 2.5523e+00, 2.6167e+00, 2.6768e+00, 2.7324e+00, 2.7831e+00,\n",
      "        2.8290e+00, 2.8696e+00, 2.9050e+00, 2.9349e+00, 2.9593e+00, 2.9780e+00,\n",
      "        2.9910e+00, 2.9983e+00], grad_fn=<CatBackward>)\n",
      "tensor([5.6680e-04, 2.9840e-03, 7.3230e-03, 1.3568e-02, 2.1695e-02, 3.1672e-02,\n",
      "        4.3461e-02, 5.7016e-02, 7.2285e-02, 8.9209e-02, 1.0772e-01, 1.2775e-01,\n",
      "        1.4922e-01, 1.7205e-01, 1.9615e-01, 2.2142e-01, 2.4777e-01, 2.7510e-01,\n",
      "        3.0329e-01, 3.3225e-01, 3.6186e-01, 3.9200e-01, 4.2255e-01, 4.5341e-01,\n",
      "        4.8445e-01, 5.1555e-01, 5.4659e-01, 5.7745e-01, 6.0800e-01, 6.3814e-01,\n",
      "        6.6775e-01, 6.9671e-01, 7.2490e-01, 7.5223e-01, 7.7858e-01, 8.0385e-01,\n",
      "        8.2795e-01, 8.5078e-01, 8.7225e-01, 8.9228e-01, 9.1079e-01, 9.2771e-01,\n",
      "        9.4298e-01, 9.5654e-01, 9.6833e-01, 9.7831e-01, 9.8643e-01, 9.9268e-01,\n",
      "        9.9702e-01, 9.9943e-01], grad_fn=<CatBackward>)\n",
      "torch.Size([50])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "torch.Size([1])\n",
      "tensor([3.], requires_grad=True)\n",
      "tensor([1.], requires_grad=True)\n",
      "torch.Size([1])\n",
      "(tensor([1.5000], dtype=torch.float64, grad_fn=<MulBackward0>), tensor([-0.5000], dtype=torch.float64, grad_fn=<MulBackward0>))\n"
     ]
    }
   ],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "model = ToyModel()\n",
    "\n",
    "# defining model input tensors\n",
    "input1 = torch.tensor([3.0], requires_grad=True)\n",
    "input2 = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "# print(model.forward(input1, input2))\n",
    "# print(model.forward(baseline1, baseline2))\n",
    "\n",
    "\n",
    "# defining baselines for each input tensor\n",
    "baseline1 = torch.tensor([0.0])\n",
    "baseline2 = torch.tensor([0.0])\n",
    "\n",
    "# defining and applying integrated gradients on ToyModel and the\n",
    "ig = IntegratedGradients(model)\n",
    "attributions, approximation_error = ig.attribute((input1, input2),\n",
    "                                                 baselines=(baseline1, baseline2),\n",
    "                                                 method='gausslegendre',\n",
    "                                                 return_convergence_delta=True)\n",
    "\n",
    "print(attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d567b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259279c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e96af816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ToySoftmaxModel(nn.Module):\n",
    "    r\"\"\"\n",
    "    Model architecture from:\n",
    "\n",
    "    https://adventuresinmachinelearning.com/pytorch-tutorial-deep-learning/\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_in, num_hidden, num_out):\n",
    "        super().__init__()\n",
    "        self.num_in = num_in\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_out = num_out\n",
    "        self.lin1 = nn.Linear(num_in, num_hidden)\n",
    "        self.lin2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.lin3 = nn.Linear(num_hidden, num_out)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        lin1 = F.relu(self.lin1(input))\n",
    "        lin2 = F.relu(self.lin2(lin1))\n",
    "        lin3 = self.lin3(lin2)\n",
    "        return self.softmax(lin3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65e0a129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 40]) torch.Size([1, 40])\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "tensor(1., grad_fn=<SumBackward0>)\n",
      "tensor(-0.0943, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "num_in = 40\n",
    "input = torch.arange(0.0, num_in * 1.0, requires_grad=True).unsqueeze(0)\n",
    "baseline = torch.tensor([0.0]*num_in, requires_grad=True).unsqueeze(0)\n",
    "\n",
    "print(input.shape, baseline.shape)\n",
    "\n",
    "# 10-class classification model\n",
    "model = ToySoftmaxModel(num_in, 20, 10)\n",
    "\n",
    "# attribution score will be computed with respect to target class\n",
    "target_class_index = 5\n",
    "\n",
    "print(torch.sum(model.forward(input)))\n",
    "print(torch.sum(model.forward(baseline)))\n",
    "\n",
    "# applying integrated gradients on the SoftmaxModel and input data point\n",
    "ig = IntegratedGradients(model)\n",
    "attributions, approximation_error = ig.attribute(input, \n",
    "                                                 baselines=baseline,\n",
    "                                                 target=target_class_index,\n",
    "                                                 return_convergence_delta=True)\n",
    "\n",
    "print(torch.sum(attributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d9e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
