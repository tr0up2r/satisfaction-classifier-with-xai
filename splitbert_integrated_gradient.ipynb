{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a8991db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.lang.en import English\n",
    "from splitbert.textsplit import text_segmentation\n",
    "from splitbert.splitbert import SplitBertConcatEncoderModel\n",
    "from splitbert.splitbert import conduct_input_ids_and_attention_masks\n",
    "from splitbert.splitbert import make_masks\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd1668f",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5a53f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seg', 'seg', 'snt']\n",
      "10 4 10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "post_df = pd.read_csv('../predicting-satisfaction-using-graphs/csv/dataset/liwc_post.csv', encoding='UTF-8')\n",
    "comment_df = pd.read_csv('../predicting-satisfaction-using-graphs/csv/dataset/liwc_comment.csv', encoding='UTF-8')\n",
    "reply_df = pd.read_csv('../predicting-satisfaction-using-graphs/csv/dataset/avg_satisfaction_raw_0-999.csv', encoding='ISO-8859-1')\n",
    "\n",
    "modes = [['seg', 'seg', 'snt']]\n",
    "\n",
    "nlp = English()\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# satisfaction score (y)\n",
    "satisfactions_float = list(reply_df['satisfy_composite'])\n",
    "satisfactions = []\n",
    "\n",
    "for s in satisfactions_float:\n",
    "    if s < 3.5:\n",
    "        satisfactions.append(0)\n",
    "    elif s < 5:\n",
    "        satisfactions.append(1)\n",
    "    else:\n",
    "        satisfactions.append(2)\n",
    "\n",
    "reply_contents = list(reply_df['replyContent'])\n",
    "post_contents = list(post_df['content'])\n",
    "comment_bodies = list(comment_df['content'])\n",
    "\n",
    "\n",
    "def get_sequences(contents, mode):\n",
    "    sequences = []\n",
    "\n",
    "    if mode == 'all':\n",
    "        for content in contents:\n",
    "            sequences.append([content])\n",
    "    elif mode == 'seg':\n",
    "        for content in contents:\n",
    "            sentences = list(map(lambda x: str(x), list(nlp(content).sents)))\n",
    "            sequences.append(text_segmentation(sentences))\n",
    "    else:  # sentences\n",
    "        for content in contents:\n",
    "            sequences.append(list(map(lambda x: str(x), list(nlp(content).sents))))\n",
    "\n",
    "    return sequences\n",
    "\n",
    "\n",
    "for mode in modes:\n",
    "    print(mode)\n",
    "    post_sequences = get_sequences(post_contents, mode[0])\n",
    "    comment_sequences = get_sequences(comment_bodies, mode[1])\n",
    "    reply_sequences = get_sequences(reply_contents, mode[2])\n",
    "\n",
    "    data = []\n",
    "    max_post, max_comment, max_reply = 0, 0, 0\n",
    "    i = 0\n",
    "    for post, comment, reply, satisfaction, satisfaction_float in zip(post_sequences, comment_sequences,\n",
    "                                                                          reply_sequences, satisfactions,\n",
    "                                                                          satisfactions_float):\n",
    "        if len(post) > max_post:\n",
    "            max_post = len(post)\n",
    "        if len(comment) > max_comment:\n",
    "            max_comment = len(comment)\n",
    "        if len(reply) > max_reply:\n",
    "            max_reply = len(reply)\n",
    "\n",
    "        data.append([i, post, comment, reply, satisfaction, satisfaction_float])\n",
    "        i += 1\n",
    "\n",
    "    print(max_post, max_comment, max_reply)\n",
    "    max_count = max(max_post, max_comment, max_reply)\n",
    "    print(max_count)\n",
    "\n",
    "    columns = ['index', 'post_contents', 'comment_contents', 'reply_contents', 'label', 'score']\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    # data split (train & test sets)\n",
    "    idx_train, idx_remain = train_test_split(df.index.values, test_size=0.20, random_state=42)\n",
    "    idx_val, idx_test = train_test_split(idx_remain, test_size=0.50, random_state=42)\n",
    "\n",
    "    train_df = df.iloc[idx_train]\n",
    "    val_df = df.iloc[idx_val]\n",
    "    test_df = df.iloc[idx_test]\n",
    "\n",
    "    count_min_label = min(train_df['label'].value_counts())\n",
    "\n",
    "    labels = [0, 1, 2]\n",
    "\n",
    "    train_sample_df = pd.DataFrame([], columns=columns)\n",
    "\n",
    "    for label in labels:\n",
    "        tmp = train_df[train_df['label'] == label]\n",
    "        tmp_sampled = tmp.sample(frac=1).iloc[:count_min_label]\n",
    "        train_sample_df = pd.concat([train_sample_df, tmp_sampled])\n",
    "\n",
    "    train_sample_df = train_sample_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e0bf40",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9f0bf5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_func_ig(inputs):\n",
    "    now = 0\n",
    "\n",
    "    for embeddings, count in zip(inputs, sentence_counts):\n",
    "        embeddings = embeddings.unsqueeze(0)\n",
    "        embeddings = embeddings.swapaxes(0, 1)\n",
    "\n",
    "        embeddings = model.pe(embeddings)\n",
    "\n",
    "        src_mask, src_key_padding_mask = make_masks(model.max_len, count, device)\n",
    "\n",
    "        encoder_output = model.encoder(embeddings, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        encoder_output = torch.mean(encoder_output[:count], dim=0)\n",
    "\n",
    "        if now == 0:\n",
    "            result_outputs = encoder_output\n",
    "        else:\n",
    "            result_outputs = torch.cat([result_outputs, encoder_output], dim=1)\n",
    "        now += 1\n",
    "    \n",
    "    outputs = model.classifier1(result_outputs)\n",
    "    logits = model.classifier2(outputs)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "01f62ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_func_ig2(inputs, sentence_counts):\n",
    "    now = 0\n",
    "\n",
    "    for encoder_output, count in zip(inputs, sentence_counts):\n",
    "        encoder_output = encoder_output.swapaxes(0, 1)\n",
    "        encoder_output = torch.mean(encoder_output[:count], dim=0)\n",
    "\n",
    "        if now == 0:\n",
    "            result_outputs = encoder_output\n",
    "        else:\n",
    "            result_outputs = torch.cat([result_outputs, encoder_output], dim=1)\n",
    "        now += 1\n",
    "        \n",
    "    outputs = model.classifier1(result_outputs)\n",
    "    logits = model.classifier2(outputs)\n",
    "    return logits\n",
    "\n",
    "ig = IntegratedGradients(forward_func_ig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e9d29b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device('cpu')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "model_path = f'../predicting-satisfaction-using-graphs/splitbert/model/seg_seg_snt/epoch_6.model'\n",
    "model = SplitBertConcatEncoderModel(num_labels=len(labels), embedding_size=384, max_len=max_count, device='cpu', pc_segmentation=False)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "for param in model.sbert.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f529f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_ref_pair(triplet):\n",
    "    input_ids_list, ref_input_ids_list, attention_masks_list, sentence_count_list = [], [], [], []\n",
    "    \n",
    "    for contents in triplet:\n",
    "        result = tokenizer(contents, pad_to_max_length=True, truncation=True, max_length=256, return_tensors='pt')\n",
    "        \n",
    "        input_ids = result['input_ids']\n",
    "        sentence_count_list.append(torch.tensor(len(input_ids)).unsqueeze(0))\n",
    "        attention_masks = result['attention_mask']\n",
    "        \n",
    "        pad = (0, 0, 0, max_count-len(input_ids))\n",
    "        input_ids = nn.functional.pad(input_ids, pad, \"constant\", 0)\n",
    "        attention_masks = nn.functional.pad(attention_masks, pad, \"constant\", 0)\n",
    "        ref_input_ids = torch.zeros_like(input_ids)\n",
    "\n",
    "        input_ids_list.append(input_ids.unsqueeze(0))\n",
    "        ref_input_ids_list.append(ref_input_ids.unsqueeze(0))\n",
    "        attention_masks_list.append(attention_masks.unsqueeze(0))\n",
    "    \n",
    "    return input_ids_list, ref_input_ids_list, attention_masks_list, sentence_count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5f2e6dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attributions(attribution):\n",
    "    attributions = attribution.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f8f207a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(post, comment, reply, p_sentences, c_sentences, r_sentences, label):\n",
    "    input_ids, ref_input_ids, attention_masks, sentence_counts = construct_input_ref_pair([post, comment, reply])\n",
    "    \n",
    "    \n",
    "    one_hot_labels = torch.nn.functional.one_hot(torch.tensor(label), num_classes=len(labels))\n",
    "    inputs = {'labels': one_hot_labels.type(torch.float).to(device),\n",
    "          'input_ids1': input_ids[0].to(device),\n",
    "          'input_ids2': input_ids[1].to(device),\n",
    "          'input_ids3': input_ids[2].to(device),\n",
    "          'attention_mask1': attention_masks[0].to(device),\n",
    "          'attention_mask2': attention_masks[1].to(device),\n",
    "          'attention_mask3': attention_masks[2].to(device),\n",
    "          'sentence_count1': sentence_counts[0].to(device),\n",
    "          'sentence_count2': sentence_counts[1].to(device),\n",
    "          'sentence_count3': sentence_counts[2].to(device),\n",
    "          'mode': 'triplet'\n",
    "         }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).hidden_states\n",
    "        \n",
    "    inputs = torch.stack(embeddings, dim=0)\n",
    "    pred = forward_func_ig2(inputs, sentence_counts)\n",
    "    print(f'answer: {label}, predict: {torch.argmax(pred)}')\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        attribution, delta = ig.attribute(inputs=inputs, target=i, additional_forward_args=sentence_counts, return_convergence_delta=True)\n",
    "        attributions = summarize_attributions(attribution)\n",
    "        f_attributions = torch.flatten(attributions)\n",
    "        f_attributions = f_attributions[f_attributions.nonzero()].squeeze(1)\n",
    "        \n",
    "        all_sentences = [post, comment, reply]\n",
    "        all_tokens = [item for all_sentences in all_sentences for item in all_sentences]\n",
    "        \n",
    "        score_vis = viz.VisualizationDataRecord(f_attributions,\n",
    "                                        torch.max(torch.softmax(pred, dim=0)),\n",
    "                                        torch.argmax(pred),  # predicted label\n",
    "                                        label,  # true label\n",
    "                                        p_sentences + ' ' + c_sentences + ' ' + r_sentences,\n",
    "                                        f_attributions.sum(),\n",
    "                                        all_tokens,\n",
    "                                        delta)\n",
    "        print(f_attributions)\n",
    "        print('\\033[1m', 'Visualization For Score', '\\033[0m')\n",
    "        viz.visualize_text([score_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a99091bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 0, predict: 0\n",
      "tensor([0.2182, 0.6925, 0.3547, 0.0668, 0.2128, 0.2503, 0.3623, 0.3215],\n",
      "       dtype=torch.float64)\n",
      "\u001b[1m Visualization For Score \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>I'm wondering if anyone here has thought about suicide methods that come close to killing you but can't.  I'm not ready to die but I want to hurt.  I want people to see physically how much I'm hurting emotionally.I've thought about jumping in front of cars or falling from non-lethal heights.  Those aren't the nicest methods but I'll go with them if I can't find a better one. Donât do these things please. If other people donât believe how hurt you are emotionally, try your best to let it not affect you. No it needs to be seen.  I've talked with people about it all I can.  They don't think I'm being realistic.  I'm capable of killing myself and one day I will if I don't get help.  Maybe sooner rather than later.  Believe it or not this is the responsible choice.</b></text></td><td><text style=\"padding-right:2em\"><b>2.48</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> I'm wondering if anyone here has thought about suicide methods that come close to killing you but can't.  I'm not ready to die but I want to hurt.  I want people to see physically how much I'm hurting emotionally. I've thought about jumping in front of cars or falling from non-lethal heights.  Those aren't the nicest methods but I'll go with them if I can't find a better one.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 66%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Donât do these things please. If other people donât believe how hurt you are emotionally, try your best to let it not affect you.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> No it needs to be seen.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  I've talked with people about it all I can.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  They don't think I'm being realistic.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  I'm capable of killing myself and one day I will if I don't get help.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  Maybe sooner rather than later.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  Believe it or not this is the responsible choice.                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4113,  0.8138, -0.1699,  0.1730,  0.2604,  0.0038, -0.1420, -0.1478],\n",
      "       dtype=torch.float64)\n",
      "\u001b[1m Visualization For Score \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>I'm wondering if anyone here has thought about suicide methods that come close to killing you but can't.  I'm not ready to die but I want to hurt.  I want people to see physically how much I'm hurting emotionally.I've thought about jumping in front of cars or falling from non-lethal heights.  Those aren't the nicest methods but I'll go with them if I can't find a better one. Donât do these things please. If other people donât believe how hurt you are emotionally, try your best to let it not affect you. No it needs to be seen.  I've talked with people about it all I can.  They don't think I'm being realistic.  I'm capable of killing myself and one day I will if I don't get help.  Maybe sooner rather than later.  Believe it or not this is the responsible choice.</b></text></td><td><text style=\"padding-right:2em\"><b>0.38</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> I'm wondering if anyone here has thought about suicide methods that come close to killing you but can't.  I'm not ready to die but I want to hurt.  I want people to see physically how much I'm hurting emotionally. I've thought about jumping in front of cars or falling from non-lethal heights.  Those aren't the nicest methods but I'll go with them if I can't find a better one.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 60%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Donât do these things please. If other people donât believe how hurt you are emotionally, try your best to let it not affect you.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> No it needs to be seen.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  I've talked with people about it all I can.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  They don't think I'm being realistic.                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  I'm capable of killing myself and one day I will if I don't get help.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  Maybe sooner rather than later.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  Believe it or not this is the responsible choice.                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0453, -0.8829, -0.1641, -0.1360, -0.2736, -0.1821, -0.2018, -0.1559],\n",
      "       dtype=torch.float64)\n",
      "\u001b[1m Visualization For Score \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>I'm wondering if anyone here has thought about suicide methods that come close to killing you but can't.  I'm not ready to die but I want to hurt.  I want people to see physically how much I'm hurting emotionally.I've thought about jumping in front of cars or falling from non-lethal heights.  Those aren't the nicest methods but I'll go with them if I can't find a better one. Donât do these things please. If other people donât believe how hurt you are emotionally, try your best to let it not affect you. No it needs to be seen.  I've talked with people about it all I can.  They don't think I'm being realistic.  I'm capable of killing myself and one day I will if I don't get help.  Maybe sooner rather than later.  Believe it or not this is the responsible choice.</b></text></td><td><text style=\"padding-right:2em\"><b>-1.95</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> I'm wondering if anyone here has thought about suicide methods that come close to killing you but can't.  I'm not ready to die but I want to hurt.  I want people to see physically how much I'm hurting emotionally. I've thought about jumping in front of cars or falling from non-lethal heights.  Those aren't the nicest methods but I'll go with them if I can't find a better one.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Donât do these things please. If other people donât believe how hurt you are emotionally, try your best to let it not affect you.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> No it needs to be seen.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  I've talked with people about it all I can.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  They don't think I'm being realistic.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  I'm capable of killing myself and one day I will if I don't get help.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  Maybe sooner rather than later.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  Believe it or not this is the responsible choice.                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 23\n",
    "main(post_sequences[N], comment_sequences[N], reply_sequences[N], post_contents[N], comment_bodies[N], reply_contents[N], satisfactions[N])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
